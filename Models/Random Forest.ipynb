{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8771eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13c5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_east_df = pd.read_csv('../CSV/NBA-teams-data-east.csv')\n",
    "curr_east_df = pd.read_csv('../CSV/NBA-2022-team-data-east.csv')\n",
    "\n",
    "train_west_df = pd.read_csv('../CSV/NBA-teams-data-west.csv')\n",
    "curr_west_df = pd.read_csv('../CSV/NBA-2022-team-data-west.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "598d2a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_east = train_east_df.drop(['Team','Year','Conf','made_playoff'], axis = 1)\n",
    "y_east = train_east_df['made_playoff']\n",
    "\n",
    "X_west = train_west_df.drop(['Team','Year','Conf','made_playoff'], axis = 1)\n",
    "y_west = train_west_df['made_playoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932b073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_east, X_test_east, y_train_east, y_test_east = train_test_split(X_east, y_east, test_size = .30,random_state=42)\n",
    "X_train_west, X_test_west, y_train_west, y_test_west = train_test_split(X_west, y_west,test_size = .30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7969af3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_east = RandomForestClassifier(oob_score = True)\n",
    "random_forest_east.fit(X_train_east,y_train_east)\n",
    "\n",
    "random_forest_west = RandomForestClassifier(oob_score = True)\n",
    "random_forest_west.fit(X_train_west,y_train_west)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5602558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest East\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.9005847953216374\n",
      "random_forest West\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.9058823529411765\n"
     ]
    }
   ],
   "source": [
    "print(\"random_forest East\")\n",
    "print(f\"Training Data Score: {random_forest_east.score(X_train_east,y_train_east)}\")\n",
    "print(f\"Testing Data Score: {random_forest_east.score(X_test_east, y_test_east)}\")\n",
    "\n",
    "print(\"random_forest West\")\n",
    "print(f\"Training Data Score: {random_forest_west.score(X_train_west, y_train_west)}\")\n",
    "print(f\"Testing Data Score: {random_forest_west.score(X_test_west, y_test_west)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a261bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07bbbcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a60da872",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4631fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a randomSearchCV to find better parameters\n",
    "RF_random_search_east = RandomizedSearchCV(estimator = RandomForest, param_distributions = random_grid,n_iter = 20, \n",
    "                                        cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "RF_random_search_west = RandomizedSearchCV(estimator = RandomForest, param_distributions = random_grid,n_iter = 20, \n",
    "                                           cv = 3, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b8a049c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_random_search_east.fit(X_train_east,y_train_east)\n",
    "RF_random_search_west.fit(X_train_west,y_train_west)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "879301f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFrandomSearchCV East\n",
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.9122807017543859\n",
      "RFrandomSearchCV West\n",
      "Training Data Score: 0.9696969696969697\n",
      "Testing Data Score: 0.9117647058823529\n"
     ]
    }
   ],
   "source": [
    "print(\"RFrandomSearchCV East\")\n",
    "print(f\"Training Data Score: {RF_random_search_east.score(X_train_east,y_train_east)}\")\n",
    "print(f\"Testing Data Score: {RF_random_search_east.score(X_test_east, y_test_east)}\")\n",
    "print(\"RFrandomSearchCV West\")\n",
    "print(f\"Training Data Score: {RF_random_search_west.score(X_train_west,y_train_west)}\")\n",
    "print(f\"Testing Data Score: {RF_random_search_west.score(X_test_west, y_test_west)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4589143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teams_east = curr_east_df['Team']\n",
    "teams_west = curr_west_df['Team']\n",
    "curr_east_df = curr_east_df.drop(['Team','Year','Conf','made_playoff'], axis = 1)\n",
    "curr_west_df = curr_west_df.drop(['Team','Year','Conf','made_playoff'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b81a5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_east = RF_random_search_east.predict(curr_east_df)\n",
    "predictions_east_prob = RF_random_search_east.predict_proba(curr_east_df)[:,1]\n",
    "predictions_west = RF_random_search_west.predict(curr_west_df)\n",
    "predictions_west_prob = RF_random_search_west.predict_proba(curr_west_df)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eebce7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Team  predictions  prediction probability\n",
      "5    Philadelphia 76ers            1                0.957222\n",
      "3    Washington Wizards            1                0.952416\n",
      "13      Milwaukee Bucks            1                0.934442\n",
      "8        Boston Celtics            1                0.925359\n",
      "9            Miami Heat            1                0.883915\n",
      "0         Chicago Bulls            1                0.880192\n",
      "12        Atlanta Hawks            1                0.878946\n",
      "14    Charlotte Hornets            1                0.866970\n",
      "11        Brooklyn Nets            1                0.828180\n",
      "6       New York Knicks            1                0.800701\n",
      "2   Cleveland Cavaliers            1                0.523712\n",
      "4       Toronto Raptors            0                0.441443\n",
      "7        Indiana Pacers            0                0.248902\n",
      "1         Orlando Magic            0                0.081640\n",
      "10      Detroit Pistons            0                0.048379\n"
     ]
    }
   ],
   "source": [
    "results_east = pd.DataFrame()\n",
    "results_east['Team'] = teams_east\n",
    "results_east['predictions'] = predictions_east\n",
    "results_east['prediction probability'] = predictions_east_prob\n",
    "print(results_east.sort_values('prediction probability', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab264887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Team  predictions  prediction probability\n",
      "5             Phoenix Suns            1                0.979040\n",
      "1                Utah Jazz            1                0.951586\n",
      "14   Golden State Warriors            1                0.936667\n",
      "6         Dallas Mavericks            1                0.783607\n",
      "7     Los Angeles Clippers            1                0.767407\n",
      "13  Portland Trail Blazers            1                0.726201\n",
      "8        Memphis Grizzlies            1                0.690869\n",
      "12      Los Angeles Lakers            1                0.648654\n",
      "4           Denver Nuggets            1                0.595147\n",
      "10  Minnesota Timberwolves            0                0.464882\n",
      "9        San Antonio Spurs            0                0.411515\n",
      "0         Sacramento Kings            0                0.135367\n",
      "11   Oklahoma City Thunder            0                0.111549\n",
      "2          Houston Rockets            0                0.106882\n",
      "3     New Orleans Pelicans            0                0.042085\n"
     ]
    }
   ],
   "source": [
    "results_west = pd.DataFrame()\n",
    "results_west['Team'] = teams_west\n",
    "results_west['predictions'] = predictions_west\n",
    "results_west['prediction probability'] = predictions_west_prob\n",
    "print(results_west.sort_values('prediction probability', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83586567",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_east['Conf'] = 'East'\n",
    "results_west['Conf'] = 'West'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3126fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([results_east,results_west])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e7cedd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../Results/Random-Forest-Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b72c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
